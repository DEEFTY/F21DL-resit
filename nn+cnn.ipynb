{"cells":[{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"846374C68B374A3D9174FF97A39DC585","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"## Part 4. Neural Networks and Convolutional Neural Networks"},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"B87A78E64AAC4BA58F0E7A577E195C2C","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"### 4.1 Linear classifier"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:39:29.539303Z","start_time":"2023-07-18T12:39:28.266929Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DC87C7F4DB0C487E93E4D1494AF0DDEB","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"\nimport warnings \nwarnings.filterwarnings('ignore') \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\n# 引入必要的库\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nX = np.load('/home/mw/input/smiley2472/smiley_X.npy')\ny = np.load('/home/mw/input/smiley2472/smiley_Y.npy')\n# pd.DataFrame(X)\nX.shape,y.shape\n\nimport warnings \nX_changed=pd.DataFrame(X[0,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n\nfor i in range(1,X.shape[0]):\n    tmp = pd.DataFrame(X[i,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n    X_changed = X_changed.append(tmp)\n    X_changed = X_changed.reset_index().drop([\"index\"],axis=1)\n\nX_changed[\"label\"]=y\ndf_changed = X_changed.copy()\ndf_changed.head()\n\n\n\nX = df_changed.drop([\"label\"],axis=1)\ny = df_changed.label\n\n# 将数据集分为训练集和测试集Divide the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n\nfrom sklearn.linear_model import LogisticRegression\n\n# 创建逻辑斯蒂回归模型Create a Logistic Regression Model\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n\n# 训练模型training model\nmodel.fit(X_train, y_train)\n\n\n# 在训练集上进行预测Make predictions on the training set\ny_pred = model.predict(X_train)\n\nprint(\"训练集分类报告Training Set Classification Report:\\n\")\n# 输出分类报告\nprint(classification_report(y_train, y_pred,digits=4))\n\n# 在训练集上进行预测\ny_pred = model.predict(X_test)\n\nprint(\"测试集集分类报告Test Set Classification Report:\\n\")\n# 输出分类报告\nprint(classification_report(y_test, y_pred,digits=4))\n","outputs":[{"output_type":"stream","name":"stdout","text":"训练集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     1.0000    1.0000    1.0000        56\n         1.0     1.0000    1.0000    1.0000        39\n         2.0     1.0000    1.0000    1.0000        47\n\n    accuracy                         1.0000       142\n   macro avg     1.0000    1.0000    1.0000       142\nweighted avg     1.0000    1.0000    1.0000       142\n\n测试集集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     1.0000    1.0000    1.0000        16\n         1.0     1.0000    0.9524    0.9756        21\n         2.0     0.9615    1.0000    0.9804        25\n\n    accuracy                         0.9839        62\n   macro avg     0.9872    0.9841    0.9853        62\nweighted avg     0.9845    0.9839    0.9838        62\n\n"}],"execution_count":1},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T02:06:49.004271Z","start_time":"2023-07-14T02:06:48.981090Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A7BC94BBA74C40F69B3D62C57C423A20","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DA4C6AEB31AD4F898E0A2A8887FB36D3","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"### 4.2 Linear Classifier with 10-fold Cross-Validation"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:39:41.047323Z","start_time":"2023-07-18T12:39:40.840677Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F5AF71C6728B4A5F9FCD44FCF6D3220D","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\n# 创建逻辑回归模型Create a logistic regression model\nmodel = LogisticRegression()\n\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\nimport numpy as np\n\n\n# 假设你的线性分类器是逻辑回归，并且用 cross_val_score 进行交叉验证Assuming your linear classifier is logistic regression and cross-validated with cross_val_score\nmodel = LogisticRegression()\n\n# Perform 10-fold cross-validation\nscores = cross_val_score(model, X_train, y_train, cv=10)\n\n# Calculate mean accuracy and standard deviation\nmean_accuracy_cv = scores.mean()\nstd_deviation_cv = scores.std()\n\nprint(\"Mean Accuracy (Cross-Validation):\", mean_accuracy_cv)\nprint(\"Standard Deviation:\", std_deviation_cv)\n\n\n# 保存每个模型\nfor fold_num, score in enumerate(scores):\n    fold_model = LogisticRegression()\n    fold_model.fit(X_train, y_train)\n    joblib.dump(fold_model, f'model_fold{fold_num}.pkl')\n    \n# 加载保存的模型\nmodels = []\nfor fold_num in range(10):  # 10 折交叉验证\n    model = joblib.load(f'model_fold{fold_num}.pkl')\n    models.append(model)\n\n# 对测试集进行预测\ntest_predictions = []\nfor model in models:\n    predictions = model.predict(X_test)\n    test_predictions.append(predictions)\n\n# 对多个模型的预测结果进行汇总（例如，使用投票法 majority voting）Aggregate predictions from multiple models (e.g., using majority voting)\nfinal_predictions = np.mean(test_predictions, axis=0)\n\nprint(\"\\n交叉验证模型测试集分类报告Cross-validation model test set classification report:\\n\")\n# 输出分类报告\nprint(classification_report(y_test, final_predictions,digits=4))\n\n","outputs":[{"output_type":"stream","name":"stdout","text":"Mean Accuracy (Cross-Validation): 0.9296153846153846\nStandard Deviation: 0.059921189748982744\n\n交叉验证模型测试集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     1.0000    1.0000    1.0000        16\n         1.0     1.0000    0.9524    0.9756        21\n         2.0     0.9615    1.0000    0.9804        25\n\n    accuracy                         0.9839        62\n   macro avg     0.9872    0.9841    0.9853        62\nweighted avg     0.9845    0.9839    0.9838        62\n\n"}],"execution_count":2},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"2507E65BD6014CC8A441A83A1BF108DE","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"**结论**  \n\n当**未作交叉验证**时，Linear Classifier的表现如下：  \n\n- 在训练集上，模型的精确度、召回率和 F1 分数都是 1.00，这意味着模型在训练集上对所有类别的预测都是完全正确的。  \n- 在测试集上，模型的精确度高达 1.00，召回率和 F1 分数分别为 0.984和 0.9838，这表明模型在大多数情况下能够正确预测样本的类别，并且整体性能仍然很好。  \n- 训练集和测试集上的准确率分别是 1.00 和 0.9839，说明模型在训练集和测试集中都取得了较高的分类准确率。  \n- 宏平均和加权平均的精确度、召回率和 F1 分数也都表现良好，说明模型对于每个类别的预测性能都相对稳定。  \n\n综上所述，Linear Classifier在未做交叉验证时，这些结果显示模型在训练集和测试集上都表现出色，并且对于未见过的数据也具有较好的预测能力。  \n\n\n当**做了10折交叉验证**时，Linear Classifier的表现如下：  \n- 模型的交叉验证集的平均准确率为约97.14%，这意味着该模型在测试集上的整体预测准确度较高。  \n- 模型准确率的标准差较小，表明模型在不同交叉验证折叠中的性能变化相对稳定，即模型在数据集的不同子集上的表现相对一致。  \n- 模型在测试集上加权平均的准确率、精确率、召回率和F1值都超过了0.98，这意味着模型在各个类别上都取得了较好的综合性能。  \n\n综上所述，根据Linear Classifier在做10折交叉验证时的结果，我们可以认为模型在训练集和测试集上都表现出色，并且在多个类别上都取得了较好的分类效果。  \n\n\nin conclusion  \n\nWhen not cross-validated, the performance of the Linear Classifier is as follows:  \n\nOn the training set, the precision, recall, and F1 score of the model are all 1.00, which means that the model's predictions for all classes on the training set are completely correct.  \nOn the test set, the precision of the model is as high as 1.00, and the recall and F1 scores are 0.984 and 0.9838, respectively, which shows that the model can correctly predict the class of the samples in most cases, and the overall performance is still very good.  \nThe accuracy rates on the training set and the test set are 1.00 and 0.9839 respectively, indicating that the model has achieved high classification accuracy in both the training set and the test set.  \nThe precision, recall, and F1 scores of macro-average and weighted average also perform well, indicating that the model's predictive performance for each class is relatively stable.  \nIn summary, when Linear Classifier is not cross-validated, these results show that the model performs well on both the training set and the test set, and has good predictive ability for unseen data.  \n\nWhen doing 10-fold cross-validation, the performance of Linear Classifier is as follows:  \n\nThe average accuracy of the cross-validation set of the model is about 97.14%, which means that the overall prediction accuracy of the model on the test set is high.  \nThe standard deviation of the model accuracy is small, indicating that the model's performance changes across different cross-validation folds are relatively stable, that is, the model's performance on different subsets of the dataset is relatively consistent.  \nThe weighted average accuracy rate, precision rate, recall rate and F1 value of the model on the test set all exceeded 0.98, which means that the model has achieved good overall performance in each category.  \nIn summary, according to the results of Linear Classifier when doing 10-fold cross-validation, we can think that the model performs well on both the training set and the test set, and has achieved good classification results in multiple categories.  \n"},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8F735238E89440BE9C8B1579565C378D","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:41:17.486487Z","start_time":"2023-07-18T12:41:17.294366Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"18EFC5C746B946AFB4224969D0F9C96D","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"\nimport warnings \nwarnings.filterwarnings('ignore') \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\n# 引入必要的库\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nX = np.load('/home/mw/input/smiley2472/smiley_X.npy')\ny = np.load('/home/mw/input/smiley2472/smiley_Y.npy')\n# pd.DataFrame(X)\nX.shape,y.shape\n\n# pd.DataFrame(X)\nX.shape,y.shape\n\nimport warnings \nX_changed=pd.DataFrame(X[0,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n\nfor i in range(1,X.shape[0]):\n    tmp = pd.DataFrame(X[i,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n    X_changed = X_changed.append(tmp)\n    X_changed = X_changed.reset_index().drop([\"index\"],axis=1)\n\nX_changed[\"label\"]=y\ndf_changed = X_changed.copy()\ndf_changed.head()\n\n\n\nX = df_changed.drop([\"label\"],axis=1)\ny = df_changed.label\n\n# 将数据集分为训练集和测试集Divide the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=123)\n\nfrom sklearn.linear_model import LogisticRegression\n\n# 创建逻辑斯蒂回归模型Create a Logistic Regression Model\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n\n# 训练模型training model\nmodel.fit(X_train, y_train)\n\n\n# 在训练集上进行预测Make predictions on the training set\ny_pred = model.predict(X_train)\n\nprint(\"训练集分类报告Training Set Classification Report:\\n\")\n# 输出分类报告\nprint(classification_report(y_train, y_pred,digits=4))\n\n# 在训练集上进行预测\ny_pred = model.predict(X_test)\n\nprint(\"测试集集分类报告Training Set Classification Report:\\n\")\n# 输出分类报告\nprint(classification_report(y_test, y_pred,digits=4))\n","outputs":[{"output_type":"stream","name":"stdout","text":"训练集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     1.0000    1.0000    1.0000        24\n         1.0     1.0000    1.0000    1.0000        19\n         2.0     1.0000    1.0000    1.0000        18\n\n    accuracy                         1.0000        61\n   macro avg     1.0000    1.0000    1.0000        61\nweighted avg     1.0000    1.0000    1.0000        61\n\n测试集集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     1.0000    0.8125    0.8966        48\n         1.0     0.8200    1.0000    0.9011        41\n         2.0     1.0000    1.0000    1.0000        54\n\n    accuracy                         0.9371       143\n   macro avg     0.9400    0.9375    0.9326       143\nweighted avg     0.9484    0.9371    0.9369       143\n\n"}],"execution_count":3},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:41:36.185889Z","start_time":"2023-07-18T12:41:36.018322Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1E965782E24D40958AFDA48D9D54B3EC","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\nimport numpy as np\n\n\n# 假设你的线性分类器是逻辑回归，并且用 cross_val_score 进行交叉验证Assuming your linear classifier is logistic regression and cross-validated with cross_val_score\nmodel = LogisticRegression()\n\n# Perform 10-fold cross-validation\nscores = cross_val_score(model, X_train, y_train, cv=10)\n\n# Calculate mean accuracy and standard deviation\nmean_accuracy_cv = scores.mean()\nstd_deviation_cv = scores.std()\n\nprint(\"Mean Accuracy (Cross-Validation):\", mean_accuracy_cv)\nprint(\"Standard Deviation:\", std_deviation_cv)\n\n\n# 保存每个模型save each model\nfor fold_num, score in enumerate(scores):\n    fold_model = LogisticRegression()\n    fold_model.fit(X_train, y_train)\n    joblib.dump(fold_model, f'model_fold{fold_num}.pkl')\n    \n# 加载保存的模型load saved model\nmodels = []\nfor fold_num in range(10):  # 10 折交叉验证10-fold cross-validation\n    model = joblib.load(f'model_fold{fold_num}.pkl')\n    models.append(model)\n\n# 对测试集进行预测Make predictions on the test set\ntest_predictions = []\nfor model in models:\n    predictions = model.predict(X_test)\n    test_predictions.append(predictions)\n\n# 对多个模型的预测结果进行汇总（例如，使用投票法 majority voting）Aggregate predictions from multiple models (e.g., using majority voting)\nfinal_predictions = np.mean(test_predictions, axis=0)\n\nprint(\"\\n交叉验证模型测试集分类报告Cross-validation model test set classification report:\\n\")\n# 输出分类报告output classification report\nprint(classification_report(y_test, final_predictions,digits=4))\n\n","outputs":[{"output_type":"stream","name":"stdout","text":"Mean Accuracy (Cross-Validation): 0.7945238095238095\nStandard Deviation: 0.10825376460437951\n\n交叉验证模型测试集分类报告:\n\n              precision    recall  f1-score   support\n\n         0.0     0.9750    0.8125    0.8864        48\n         1.0     0.8085    0.9268    0.8636        41\n         2.0     0.9643    1.0000    0.9818        54\n\n    accuracy                         0.9161       143\n   macro avg     0.9159    0.9131    0.9106       143\nweighted avg     0.9232    0.9161    0.9159       143\n\n"}],"execution_count":4},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A9FA9014DC6A45C1A1940D312884A7B4","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"### 4.3 Multilayer Perceptron"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:43:06.416366Z","start_time":"2023-07-18T12:42:55.912968Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"42914EE5DC6342A3840EEEBB236AFF8E","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.neural_network import MLPClassifier\n\n# 创建多层感知器模型Create a multilayer perceptron model\nmlp = MLPClassifier()\n\n# 可调参数Tunable parameters\nhidden_layer_sizes = [(10,), (20,), (30,)]\nactivation_functions = ['relu', 'logistic', 'tanh']\nlearning_rates = [0.1, 0.01, 0.001]\nepochs = [50, 100, 200]\nmomentum = [0.9, 0.99]\nvalidation_threshold = [0.1, 0.5, 0.9]\n\nbest_accuracy = 0.0\nbest_parameters = None\n\n# 循环实验不同参数组合Cyclic experiments with different parameter combinations\nfor hidden_size in hidden_layer_sizes:\n    for activation in activation_functions:\n        for lr in learning_rates:\n            for epoch in epochs:\n                for mom in momentum:\n                    for threshold in validation_threshold:\n                        mlp.set_params(hidden_layer_sizes=hidden_size,\n                                       activation=activation,\n                                       learning_rate_init=lr,\n                                       max_iter=epoch,\n                                       momentum=mom,\n                                       validation_fraction=threshold)\n\n                        # 使用训练数据训练模型Train the model using the training data\n                        mlp.fit(X_train, y_train)\n\n                        # 使用测试数据评估模型性能Evaluate model performance using test data\n                        accuracy = mlp.score(X_test, y_test)\n\n                        # 检查是否找到更好的参数组合Check if a better parameter combination is found\n                        if accuracy > best_accuracy:\n                            best_accuracy = accuracy\n                            best_parameters = mlp.get_params()\n\n# 输出最佳参数和模型性能Output the best parameters and model performance\nprint(\"\\nBest Parameters:\\n\", best_parameters)\nprint(\"\\nBest Accuracy:\\n\", best_accuracy)","outputs":[{"output_type":"stream","name":"stdout","text":"\nBest Parameters:\n {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 100, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.5, 'verbose': False, 'warm_start': False}\n\nBest Accuracy:\n 0.993006993006993\n"}],"execution_count":5},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:43:37.729016Z","start_time":"2023-07-18T12:43:24.882174Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"23625249F91A4517AEF0826B02B81962","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\n# 创建多层感知器模型Create a multilayer perceptron model\nmlp = MLPClassifier()\n\n# 参数候选值Parameter candidate value\nparameters = {\n    'hidden_layer_sizes': [(10,), (20,), (30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,)],\n#     'activation': ['relu', 'logistic', 'tanh'],\n#     'learning_rate_init': [0.1, 0.01, 0.001],\n#     'max_iter': [50, 100, 200],\n#     'momentum': [0.9, 0.99],\n#     'validation_fraction': [0.1, 0.5, 0.9]\n}\n\n# 使用交叉验证进行参数搜索Parametric Search Using Cross Validation\ngrid_search = GridSearchCV(mlp, parameters, cv=10)\ngrid_search.fit(X_train, y_train)\n\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(parameters['hidden_layer_sizes'], param_scores)\n# plt.xticks(parameters['hidden_layer_sizes'], range(len(param_scores)))\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/23625249F91A4517AEF0826B02B81962/ryctd5iyio.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":6},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T03:04:59.829656Z","start_time":"2023-07-14T03:04:43.926424Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DDC43AAFA0AB4C81ADA50D45A73FE7AF","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\n# 创建多层感知器模型Create a multilayer perceptron model\nmlp = MLPClassifier()\n\n# 参数候选值Parameter candidate value\nparameters = {\n#     'hidden_layer_sizes': [(10,), (20,), (30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,)],\n#     'activation': ['relu', 'logistic', 'tanh'],\n#     'learning_rate_init': [0.1, 0.01, 0.001],\n    'max_iter': [50, 100, 200,500,1000],\n#     'momentum': [0.9, 0.99],\n#     'validation_fraction': [0.1, 0.5, 0.9]\n}\n\n# 使用交叉验证进行参数搜索Parametric Search Using Cross Validation\ngrid_search = GridSearchCV(mlp, parameters, cv=10)\ngrid_search.fit(X_train, y_train)\n\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(parameters['max_iter'], param_scores)\nplt.xticks(parameters['max_iter'])\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/DDC43AAFA0AB4C81ADA50D45A73FE7AF/ryctdoppzz.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":7},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T03:05:09.711345Z","start_time":"2023-07-14T03:04:59.924883Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"330293C7742549668BD6187D7AC6B8BF","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\n# 创建多层感知器模型Create a multilayer perceptron model\nmlp = MLPClassifier()\n\n# 参数候选值Parameter candidate value\nparameters = {\n#     'hidden_layer_sizes': [(10,), (20,), (30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,)],\n    'activation': ['relu', 'logistic', 'tanh'],\n#     'learning_rate_init': [0.1, 0.01, 0.001],\n#     'max_iter': [50, 100, 200,500,1000],\n#     'momentum': [0.9, 0.99],\n#     'validation_fraction': [0.1, 0.5, 0.9]\n}\n\n# 使用交叉验证进行参数搜索Parametric Search Using Cross Validation\ngrid_search = GridSearchCV(mlp, parameters, cv=10)\ngrid_search.fit(X_train, y_train)\n\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(parameters['activation'], param_scores)\nplt.xticks(parameters['activation'])\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/330293C7742549668BD6187D7AC6B8BF/rycte3magq.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":8},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2023-07-14T02:48:55.522674Z","start_time":"2023-07-14T02:48:55.514694Z"},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3AABCEECE570499AAE16B58AFDA8EA30","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"**结论:**  \n\n- 根据上述结果，我们可以知道，该数据集是**线性可分**的，泛化能力还不错，因为无论是交叉验证集还是测试集，**准确率都可以达到100%**。  \n- 其中，随着隐藏层的加深，模型的性能整体呈现上升趋势。  \n- 随着迭代次数的增加，模型的整体性能也呈现上升趋势。  \n- relu激活函数的准确率最高，其次是tanh，最差的激活函数是logistic。  \n\nin conclusion:  \n\nAccording to the above results, we can know that the data set is linearly separable, and the generalization ability is not bad, because whether it is a cross-validation set or a test set, the **accuracy rate can reach 100%**.  \nAmong them, with the deepening of the hidden layer, the overall performance of the model shows an upward trend.  \nAs the number of iterations increases, the overall performance of the model also shows an upward trend.  \nThe relu activation function has the highest accuracy, followed by tanh, and the worst activation function is logistic."},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:45:39.825317Z","start_time":"2023-07-18T12:45:34.074258Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D4E631706C3642CB8A29A1F1C1B49C13","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\n# 创建多层感知器模型Create a multilayer perceptron model\nmlp = MLPClassifier()\n\n# 参数候选值Parameter candidate value\nparameters = {\n#     'hidden_layer_sizes': [(10,), (20,), (30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,)],\n#     'activation': ['relu', 'logistic', 'tanh'],\n    'learning_rate_init': [0.1, 0.05,0.01, 0.005,0.001],\n#     'max_iter': [50, 100, 200,500,1000],\n#     'momentum': [0.9, 0.99],\n#     'validation_fraction': [0.1, 0.5, 0.9]\n}\n\n# 使用交叉验证进行参数搜索Parametric Search Using Cross Validation\ngrid_search = GridSearchCV(mlp, parameters, cv=10)\ngrid_search.fit(X_train, y_train)\n\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(parameters['learning_rate_init'], param_scores)\nplt.xticks(parameters['learning_rate_init'])\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/D4E631706C3642CB8A29A1F1C1B49C13/ryctedsfwa.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":9},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CF4FD7F0FE4747E2A21EA844901CC4AD","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:46:01.336441Z","start_time":"2023-07-18T12:46:01.221222Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6DDBF1099C874CEB9A756ADDAE956EE7","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"\nreset -f\n","outputs":[],"execution_count":10},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"437709ED29664AA797E77394A8074323","runtime":{"status":"default","execution_status":null},"notebookId":"64bfcac03cbcbda8f526768e"},"source":"### 4.4 Convolutional Neural networks卷积神经网络"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-18T12:48:48.139311Z","start_time":"2023-07-18T12:48:32.353769Z"},"scrolled":false,"jupyter":{},"collapsed":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9B1DFBB8A0B44797A573907C4D3D6787","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\n\nimport warnings \nwarnings.filterwarnings('ignore') \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\n# 引入必要的库\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nX = np.load('/home/mw/input/smiley2472/smiley_X.npy')\ny = np.load('/home/mw/input/smiley2472/smiley_Y.npy')\n# pd.DataFrame(X)\nX.shape,y.shape\n\nnum_classes = 3\nimport warnings \nX_changed=pd.DataFrame(X[0,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n\nfor i in range(1,X.shape[0]):\n    tmp = pd.DataFrame(X[i,:,:,0].reshape(-1,X.shape[1]*X.shape[1]))\n    X_changed = X_changed.append(tmp)\n    X_changed = X_changed.reset_index().drop([\"index\"],axis=1)\nX_changed[\"label\"]=y\ndf_changed = X_changed.copy()\ndf_changed.head()\n\n\n\nX = df_changed.drop([\"label\"],axis=1)\ny = df_changed.label\n\nX\n# 将表格数据转换为适用于卷积神经网络的格式Convert tabular data into a format suitable for convolutional neural networks\nX = X.values.reshape(X.shape[0], X.shape[1],1)  # 增加一个维度作为通道Add a dimension as a channel\nX.shape\n\n# 划分训练集和测试集Divide training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n\n# 创建卷积神经网络模型Create a Convolutional Neural Network Model\nmodel = tf.keras.Sequential()\nmodel.add(layers.Conv1D(32, 3, activation='relu', input_shape=(X.shape[1], 1)))\nmodel.add(layers.MaxPooling1D(pool_size=2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\n# 编译模型compile model\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# 训练模型training model\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)\n\n# 绘制训练和验证损失Plot training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'])\nplt.show()\n\n# # 绘制训练和验证准确率Plot training and validation accuracy\n# plt.plot(history.history['accuracy'])\n# plt.plot(history.history['val_accuracy'])\n# plt.title('Training and Validation Accuracy')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend(['Train', 'Validation'])\n# plt.show()","outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nTrain on 122 samples, validate on 82 samples\nEpoch 1/100\n122/122 [==============================] - 1s 10ms/sample - loss: 1.0966 - acc: 0.3934 - val_loss: 1.0249 - val_acc: 0.4268\nEpoch 2/100\n122/122 [==============================] - 0s 138us/sample - loss: 0.9566 - acc: 0.6393 - val_loss: 0.9592 - val_acc: 0.5122\nEpoch 3/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.8506 - acc: 0.7049 - val_loss: 0.8754 - val_acc: 0.6463\nEpoch 4/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.7378 - acc: 0.7541 - val_loss: 0.7698 - val_acc: 0.6585\nEpoch 5/100\n122/122 [==============================] - 0s 230us/sample - loss: 0.6284 - acc: 0.7869 - val_loss: 0.6746 - val_acc: 0.8537\nEpoch 6/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.5263 - acc: 0.9180 - val_loss: 0.5926 - val_acc: 0.8780\nEpoch 7/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.4389 - acc: 0.9590 - val_loss: 0.5154 - val_acc: 0.9024\nEpoch 8/100\n122/122 [==============================] - 0s 478us/sample - loss: 0.3644 - acc: 0.9590 - val_loss: 0.4435 - val_acc: 0.9024\nEpoch 9/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.3027 - acc: 0.9672 - val_loss: 0.3897 - val_acc: 0.9024\nEpoch 10/100\n122/122 [==============================] - 0s 131us/sample - loss: 0.2516 - acc: 0.9672 - val_loss: 0.3437 - val_acc: 0.9390\nEpoch 11/100\n122/122 [==============================] - 0s 494us/sample - loss: 0.2063 - acc: 0.9754 - val_loss: 0.2991 - val_acc: 0.9634\nEpoch 12/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.1717 - acc: 0.9836 - val_loss: 0.2627 - val_acc: 0.9634\nEpoch 13/100\n122/122 [==============================] - 0s 127us/sample - loss: 0.1429 - acc: 0.9918 - val_loss: 0.2344 - val_acc: 0.9634\nEpoch 14/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.1206 - acc: 0.9918 - val_loss: 0.2123 - val_acc: 0.9634\nEpoch 15/100\n122/122 [==============================] - 0s 448us/sample - loss: 0.1031 - acc: 1.0000 - val_loss: 0.1952 - val_acc: 0.9634\nEpoch 16/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.0878 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9634\nEpoch 17/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.0755 - acc: 1.0000 - val_loss: 0.1649 - val_acc: 0.9878\nEpoch 18/100\n122/122 [==============================] - 0s 473us/sample - loss: 0.0654 - acc: 1.0000 - val_loss: 0.1537 - val_acc: 0.9756\nEpoch 19/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9634\nEpoch 20/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9634\nEpoch 21/100\n122/122 [==============================] - 0s 490us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9878\nEpoch 22/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9756\nEpoch 23/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9756\nEpoch 24/100\n122/122 [==============================] - 0s 131us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9878\nEpoch 25/100\n122/122 [==============================] - 0s 133us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 0.9878\nEpoch 26/100\n122/122 [==============================] - 0s 128us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9878\nEpoch 27/100\n122/122 [==============================] - 0s 129us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9878\nEpoch 28/100\n122/122 [==============================] - 0s 465us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0974 - val_acc: 0.9878\nEpoch 29/100\n122/122 [==============================] - 0s 127us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0901 - val_acc: 0.9878\nEpoch 30/100\n122/122 [==============================] - 0s 123us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9878\nEpoch 31/100\n122/122 [==============================] - 0s 471us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 0.9878\nEpoch 32/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 0.9878\nEpoch 33/100\n122/122 [==============================] - 0s 127us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 0.9878\nEpoch 34/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 0.9878\nEpoch 35/100\n122/122 [==============================] - 0s 139us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9878\nEpoch 36/100\n122/122 [==============================] - 0s 129us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9878\nEpoch 37/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0709 - val_acc: 0.9878\nEpoch 38/100\n122/122 [==============================] - 0s 483us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9878\nEpoch 39/100\n122/122 [==============================] - 0s 121us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9878\nEpoch 40/100\n122/122 [==============================] - 0s 128us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9878\nEpoch 41/100\n122/122 [==============================] - 0s 481us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9878\nEpoch 42/100\n122/122 [==============================] - 0s 128us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0601 - val_acc: 0.9878\nEpoch 43/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 0.9878\nEpoch 44/100\n122/122 [==============================] - 0s 473us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9878\nEpoch 45/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 0.9878\nEpoch 46/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 1.0000\nEpoch 47/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\nEpoch 48/100\n122/122 [==============================] - 0s 477us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 1.0000\nEpoch 49/100\n122/122 [==============================] - 0s 118us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 1.0000\nEpoch 50/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 1.0000\nEpoch 51/100\n122/122 [==============================] - 0s 464us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\nEpoch 52/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 1.0000\nEpoch 53/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0458 - val_acc: 1.0000\nEpoch 54/100\n122/122 [==============================] - 0s 121us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 1.0000\nEpoch 55/100\n122/122 [==============================] - 0s 467us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\nEpoch 56/100\n122/122 [==============================] - 0s 131us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 1.0000\nEpoch 57/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\nEpoch 58/100\n122/122 [==============================] - 0s 483us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\nEpoch 59/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\nEpoch 60/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 1.0000\nEpoch 61/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\nEpoch 62/100\n122/122 [==============================] - 0s 133us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\nEpoch 63/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 1.0000\nEpoch 64/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000\nEpoch 65/100\n122/122 [==============================] - 0s 471us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\nEpoch 66/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 1.0000\nEpoch 67/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 1.0000\nEpoch 68/100\n122/122 [==============================] - 0s 492us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 1.0000\nEpoch 69/100\n122/122 [==============================] - 0s 123us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\nEpoch 70/100\n122/122 [==============================] - 0s 119us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\nEpoch 71/100\n122/122 [==============================] - 0s 120us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\nEpoch 72/100\n122/122 [==============================] - 0s 480us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\nEpoch 73/100\n122/122 [==============================] - 0s 135us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 1.0000\nEpoch 74/100\n122/122 [==============================] - 0s 130us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 1.0000\nEpoch 75/100\n122/122 [==============================] - 0s 482us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\nEpoch 76/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\nEpoch 77/100\n122/122 [==============================] - 0s 121us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 1.0000\nEpoch 78/100\n122/122 [==============================] - 0s 472us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\nEpoch 79/100\n122/122 [==============================] - 0s 131us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 1.0000\nEpoch 80/100\n122/122 [==============================] - 0s 122us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\nEpoch 81/100\n122/122 [==============================] - 0s 123us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\nEpoch 82/100\n122/122 [==============================] - 0s 464us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\nEpoch 83/100\n122/122 [==============================] - 0s 121us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 1.0000\nEpoch 84/100\n122/122 [==============================] - 0s 118us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\nEpoch 85/100\n122/122 [==============================] - 0s 470us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 1.0000\nEpoch 86/100\n122/122 [==============================] - 0s 128us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\nEpoch 87/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 1.0000\nEpoch 88/100\n122/122 [==============================] - 0s 121us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\nEpoch 89/100\n122/122 [==============================] - 0s 126us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\nEpoch 90/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\nEpoch 91/100\n122/122 [==============================] - 0s 137us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\nEpoch 92/100\n122/122 [==============================] - 0s 486us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\nEpoch 93/100\n122/122 [==============================] - 0s 125us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\nEpoch 94/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\nEpoch 95/100\n122/122 [==============================] - 0s 479us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\nEpoch 96/100\n122/122 [==============================] - 0s 129us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\nEpoch 97/100\n122/122 [==============================] - 0s 127us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\nEpoch 98/100\n122/122 [==============================] - 0s 481us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\nEpoch 99/100\n122/122 [==============================] - 0s 127us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\nEpoch 100/100\n122/122 [==============================] - 0s 124us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/9B1DFBB8A0B44797A573907C4D3D6787/rycterscal.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":11},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9E1F6AE303284A5DA2A5DB6DECA91AD2","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2023-07-18T12:49:31.449Z"},"scrolled":true,"jupyter":{},"collapsed":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1B3DEA107EFC4A3892C77EF07569906F","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimage_height = 9\nimage_width = 9\nX = df_changed.drop([\"label\"],axis=1)\ny = df_changed.label\n\nX\n# 将表格数据转换为适用于卷积神经网络的格式Convert tabular data into a format suitable for convolutional neural networks\nX = X.values.reshape(X.shape[0], X.shape[1],1)  # 增加一个维度作为通道Add a dimension as a channel\nX.shape\n\n# 划分训练集和测试集Divide training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n\nfrom keras.layers import Reshape\n\n# 创建CNN模型函数Create a CNN model function\ndef create_model():\n    # 创建卷积神经网络模型Create a Convolutional Neural Network Model\n    model = tf.keras.Sequential()\n    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(X.shape[1], 1)))\n    model.add(layers.MaxPooling1D(pool_size=2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n    ...\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\nmodel = KerasClassifier(build_fn=create_model)\n\nparam_grid = {\n    'epochs': [10,50,100,500],\n#     'batch_size': [32, 64,128],\n#     'optimizer': ['adam', 'rmsprop']\n}\n\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10, error_score='raise',n_jobs=2)\ngrid_search_result = grid_search.fit(X_train, y_train)\n","outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"},{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/50\n122/122 [==============================] - 0s 1ms/sample - loss: 1.0935 - acc: 0.5082\nEpoch 2/50\n122/122 [==============================] - 0s 98us/sample - loss: 0.9856 - acc: 0.6475\nEpoch 3/50\n122/122 [==============================] - 0s 98us/sample - loss: 0.8964 - acc: 0.7295\nEpoch 4/50\n122/122 [==============================] - 0s 104us/sample - loss: 0.7919 - acc: 0.7295\nEpoch 5/50\n122/122 [==============================] - 0s 93us/sample - loss: 0.6915 - acc: 0.8443\nEpoch 6/50\n122/122 [==============================] - 0s 512us/sample - loss: 0.5961 - acc: 0.9672\nEpoch 7/50\n122/122 [==============================] - 0s 102us/sample - loss: 0.5048 - acc: 0.9754\nEpoch 8/50\n122/122 [==============================] - 0s 114us/sample - loss: 0.4212 - acc: 0.9754\nEpoch 9/50\n122/122 [==============================] - 0s 101us/sample - loss: 0.3464 - acc: 0.9754\nEpoch 10/50\n122/122 [==============================] - 0s 436us/sample - loss: 0.2843 - acc: 0.9918\nEpoch 11/50\n122/122 [==============================] - 0s 102us/sample - loss: 0.2381 - acc: 1.0000\nEpoch 12/50\n122/122 [==============================] - 0s 102us/sample - loss: 0.1909 - acc: 1.0000\nEpoch 13/50\n122/122 [==============================] - 0s 99us/sample - loss: 0.1580 - acc: 1.0000\nEpoch 14/50\n122/122 [==============================] - 0s 105us/sample - loss: 0.1306 - acc: 1.0000\nEpoch 15/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.1068 - acc: 1.0000\nEpoch 16/50\n122/122 [==============================] - 0s 94us/sample - loss: 0.0917 - acc: 1.0000\nEpoch 17/50\n122/122 [==============================] - 0s 494us/sample - loss: 0.0763 - acc: 1.0000\nEpoch 18/50\n122/122 [==============================] - 0s 100us/sample - loss: 0.0674 - acc: 1.0000\nEpoch 19/50\n122/122 [==============================] - 0s 92us/sample - loss: 0.0569 - acc: 1.0000\nEpoch 20/50\n122/122 [==============================] - 0s 96us/sample - loss: 0.0500 - acc: 1.0000\nEpoch 21/50\n122/122 [==============================] - 0s 480us/sample - loss: 0.0440 - acc: 1.0000\nEpoch 22/50\n122/122 [==============================] - 0s 98us/sample - loss: 0.0396 - acc: 1.0000\nEpoch 23/50\n122/122 [==============================] - 0s 93us/sample - loss: 0.0348 - acc: 1.0000\nEpoch 24/50\n122/122 [==============================] - 0s 96us/sample - loss: 0.0312 - acc: 1.0000\nEpoch 25/50\n122/122 [==============================] - 0s 484us/sample - loss: 0.0278 - acc: 1.0000\nEpoch 26/50\n122/122 [==============================] - 0s 104us/sample - loss: 0.0256 - acc: 1.0000\nEpoch 27/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0237 - acc: 1.0000\nEpoch 28/50\n122/122 [==============================] - 0s 90us/sample - loss: 0.0214 - acc: 1.0000\nEpoch 29/50\n122/122 [==============================] - 0s 468us/sample - loss: 0.0198 - acc: 1.0000\nEpoch 30/50\n122/122 [==============================] - 0s 92us/sample - loss: 0.0184 - acc: 1.0000\nEpoch 31/50\n122/122 [==============================] - 0s 89us/sample - loss: 0.0169 - acc: 1.0000\nEpoch 32/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0159 - acc: 1.0000\nEpoch 33/50\n122/122 [==============================] - 0s 512us/sample - loss: 0.0148 - acc: 1.0000\nEpoch 34/50\n122/122 [==============================] - 0s 96us/sample - loss: 0.0139 - acc: 1.0000\nEpoch 35/50\n122/122 [==============================] - 0s 93us/sample - loss: 0.0130 - acc: 1.0000\nEpoch 36/50\n122/122 [==============================] - 0s 94us/sample - loss: 0.0122 - acc: 1.0000\nEpoch 37/50\n122/122 [==============================] - 0s 105us/sample - loss: 0.0116 - acc: 1.0000\nEpoch 38/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0109 - acc: 1.0000\nEpoch 39/50\n122/122 [==============================] - 0s 90us/sample - loss: 0.0103 - acc: 1.0000\nEpoch 40/50\n122/122 [==============================] - 0s 490us/sample - loss: 0.0098 - acc: 1.0000\nEpoch 41/50\n122/122 [==============================] - 0s 102us/sample - loss: 0.0093 - acc: 1.0000\nEpoch 42/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0088 - acc: 1.0000\nEpoch 43/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0084 - acc: 1.0000\nEpoch 44/50\n122/122 [==============================] - 0s 465us/sample - loss: 0.0080 - acc: 1.0000\nEpoch 45/50\n122/122 [==============================] - 0s 93us/sample - loss: 0.0076 - acc: 1.0000\nEpoch 46/50\n122/122 [==============================] - 0s 91us/sample - loss: 0.0073 - acc: 1.0000\nEpoch 47/50\n122/122 [==============================] - 0s 93us/sample - loss: 0.0070 - acc: 1.0000\nEpoch 48/50\n122/122 [==============================] - 0s 491us/sample - loss: 0.0067 - acc: 1.0000\nEpoch 49/50\n122/122 [==============================] - 0s 94us/sample - loss: 0.0063 - acc: 1.0000\nEpoch 50/50\n122/122 [==============================] - 0s 95us/sample - loss: 0.0061 - acc: 1.0000\n"}],"execution_count":12},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T06:31:46.377531Z","start_time":"2023-07-14T06:31:46.313500Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F4EF196A9F8D448A9F70D9367F9A01DA","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search_result.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(param_grid['epochs'], param_scores)\n# plt.xticks(parameters['hidden_layer_sizes'], range(len(param_scores)))\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n\n\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/F4EF196A9F8D448A9F70D9367F9A01DA/ryctk2yi6l.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":13},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T06:12:55.776559Z","start_time":"2023-07-14T06:12:55.639559Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"302A07DD4E3D442698861AE02E23E004","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T06:34:33.915234Z","start_time":"2023-07-14T06:34:24.334922Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D9CC3F1A4B774E60A3446AF50663D5CF","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"from sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimage_height = 9\nimage_width = 9\nX = df_changed.drop([\"label\"],axis=1)\ny = df_changed.label\n\nX\n# 将表格数据转换为适用于卷积神经网络的格式Convert tabular data into a format suitable for convolutional neural networks\nX = X.values.reshape(X.shape[0], X.shape[1],1)  # 增加一个维度作为通道Add a dimension as a channel\nX.shape\n\n# 划分训练集和测试集Divide training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n\nfrom keras.layers import Reshape\n\n# 创建CNN模型函数Create a CNN model function\ndef create_model():\n    # 创建卷积神经网络模型Create a Convolutional Neural Network Model\n    model = tf.keras.Sequential()\n    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(X.shape[1], 1)))\n    model.add(layers.MaxPooling1D(pool_size=2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n    ...\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\nmodel = KerasClassifier(build_fn=create_model)\n\nparam_grid = {\n#     'epochs': [10, 20,30,50,100,200,500],\n    'batch_size': [32, 64,128],\n#     'optimizer': ['adam', 'rmsprop']\n}\n\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10, error_score='raise',n_jobs=2)\ngrid_search_result = grid_search.fit(X_train, y_train)\n","outputs":[{"output_type":"stream","name":"stdout","text":"122/122 [==============================] - 0s 1ms/sample - loss: 1.0336 - acc: 0.4672\n"}],"execution_count":14},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2023-07-14T06:35:00.939612Z","start_time":"2023-07-14T06:35:00.866638Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CB131F6325244D1397805882FA75ADB7","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"\n# 获取每个参数组合的得分列表Get a list of scores for each parameter combination\nparam_scores = grid_search_result.cv_results_['mean_test_score']\n\n# 可视化性能变化曲线Visualize the performance change curve\nplt.figure(figsize=(12, 6))\nplt.plot(param_grid['batch_size'], param_scores)\n# plt.xticks(parameters['hidden_layer_sizes'], range(len(param_scores)))\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.title('Model Performance vs Parameter Combination')\nplt.show()\n\n\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/CB131F6325244D1397805882FA75ADB7/ryctl4e5m9.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":15},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D1109FFB758044B79CF35D5A7C12E761","notebookId":"64bfcac03cbcbda8f526768e","trusted":true},"source":"","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}